{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "q3_char-rnn-generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPKTqQ3W8qLt"
      },
      "source": [
        "To begin copy this notebook to your own drive:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "### Submission Instructions:\n",
        "1. **Restart the kernel** (in the menubar, select Runtime$\\rightarrow$Restart runtime)\n",
        "2. **Run all cells** (in the menubar, select Runtime$\\rightarrow$Run All).\n",
        "3. **Download the notebook** (in the menubar, select File$\\rightarrow$Download .ipynb)\n",
        "4. **Upload the downloaded notebook (.ipynb file) to your repository**.\n",
        "\n",
        "Note: To use a GPU, do the following: Runtime$\\rightarrow$Change runtime type$\\rightarrow$ GPU\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE`, and that no tests fail.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5493400e8b7f9a8e2cde874866d4fa7f",
          "grade": false,
          "grade_id": "cell-3a1bca1dbb7d0069",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XvPkt7Zm8qLt"
      },
      "source": [
        "![shakespeare](https://i.imgur.com/81YZuel.jpg)\n",
        "\n",
        "# Generating Shakespeare Using a Character-level Language Model\n",
        "\n",
        "### From Words to Characters\n",
        "In the previous two sections we dealt with word-level language models. But looking again at section 2, there is nothing that constraints us to using _words_ as the basic elemnents in our model. The model we analyzed in section 2 could just as well be character-based - just replace \"word\" with \"character\", and you are good to go. In this notebook we will train a small character-based language model that will help us generate Shakespearean-like (emphasis on the _like_...) texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9af7a343d0e3524c3fd846d987d766a8",
          "grade": false,
          "grade_id": "cell-7301754e4d655d01",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "EvGyr_ux8qLt"
      },
      "source": [
        "### Question 3.a\n",
        "Can you think of an advantage a character-based language model could have over a word-based language model? And what about the other way around: can you think of an advantage a word-based language model could have over a character-based language model? (Add your answer to the final submission pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d46a8dfd340b8f68e51a041307f7d7d3",
          "grade": false,
          "grade_id": "cell-ebc0d8ae3061c0fc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ghCevRFf8qLt"
      },
      "source": [
        "### Using PyTorch\n",
        "\n",
        "We'll build our language model using PyTorch. PyTorch is a [very popular](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) open-source machine learning (and deep learning) framework developed by Facebook. In short:\n",
        "\n",
        "> Pytorch is a Python-based scientific computing package targeted at two sets of audiences:\n",
        "* A replacement for NumPy to use the power of GPUs\n",
        "* A deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "To get familiar with PyTorch, check out this [quick tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html). In addition, another imporant difference from numpy is that PyTorch can automatically calculate the gradients needed for backpropagation, as explained [here](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "02af8a21a2e8fae58d84f915de5b016d",
          "grade": false,
          "grade_id": "cell-aa2773db1bef7014",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MYd79g6k8qLt"
      },
      "source": [
        "### Preparing the Data\n",
        "\n",
        "Our dataset is a plain text file. For simplicity, we turn any potential unicode characters into plain ASCII by using the `unidecode` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT5WdSbsFT1K",
        "outputId": "40fbbd95-3c38-451d-fa24-5311e57f9476"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 33.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 30.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ef0359e8c08b2057771c115150011e7e",
          "grade": false,
          "grade_id": "cell-cce75419c097f3fd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "RYqFoQgV8qLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d51361a-c17a-42df-d4d2-77e3e7e22205"
      },
      "source": [
        "import string\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import unidecode\n",
        "url = \"https://github.com/tau-nlp-course/NLP_HW2/raw/main/data/shakespeare.txt\"\n",
        "\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)  # our vocabulary size (|V| from the handout)\n",
        "\n",
        "dataset_as_string = unidecode.unidecode(requests.get(url).content.decode())\n",
        "n_chars_in_dataset = len(dataset_as_string)\n",
        "print(f'Total number of characters in our dataset: {n_chars_in_dataset}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters in our dataset: 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "06dd2ac91a6296206475c7e330e53e3d",
          "grade": false,
          "grade_id": "cell-d795f907dd7922f3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "mIctyT3J8qLu"
      },
      "source": [
        "To make inputs out of this big string of text, we will split it into chunks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "61947ad22fb7f16eba246d47ab8cae22",
          "grade": false,
          "grade_id": "cell-379f229536dae19b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "eoLs0ivz8qLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1a5c93-50ad-4239-902f-fc6b32c09bc1"
      },
      "source": [
        "chunk_len = 400\n",
        "\n",
        "def random_chunk():\n",
        "    start_index = random.randint(0, n_chars_in_dataset - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return dataset_as_string[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "down:\n",
            "The which shall point you forth at every sitting\n",
            "What you must say; that he shall not perceive\n",
            "But that you have your father's bosom there\n",
            "And speak his very heart.\n",
            "\n",
            "FLORIZEL:\n",
            "I am bound to you:\n",
            "There is some sap in this.\n",
            "\n",
            "CAMILLO:\n",
            "A cause more promising\n",
            "Than a wild dedication of yourselves\n",
            "To unpath'd waters, undream'd shores, most certain\n",
            "To miseries enough; no hope to help you,\n",
            "But as you \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ba5d4900ff254fa335fe935962878c8d",
          "grade": false,
          "grade_id": "cell-fcbb2d73f4e442fb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ho8WlUcV8qLv"
      },
      "source": [
        "### Building Our Model\n",
        "\n",
        "Our model consists of three main components:\n",
        "\n",
        "1. [**Embedding**](https://pytorch.org/docs/stable/nn.html#embedding). A mapping between characters and their learned representations (\"word vectors\") \\[correspoding to ${\\boldsymbol L}$ in terms of the handout\\]\n",
        "2. [**GRU**](https://pytorch.org/docs/stable/nn.html#gru). \\[correspoding to the computation of ${\\boldsymbol h}^{(t)}$ in terms of the handout\\]\n",
        "3. **Output Layer**. A feed-forward neural network that transforms a hidden state at a timestep into a probability distribution of the next character. \\[correspoding to the computation of $\\hat{\\boldsymbol y}^{(t)}$ in terms of the handout\\] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFm8g2pd8qLv"
      },
      "source": [
        "### Question 3.b\n",
        "Complete the implementation of the `forward` method of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a9ad1239fcd5aec23f439249397895ec",
          "grade": false,
          "grade_id": "cell-1640492438386e87",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "2SoCQ_ZM8qLv"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class OurModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(OurModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)  # In the terms of the handout, here d = D_h\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input_, hidden):\n",
        "        # General instructions:\n",
        "        # Pass the embedded input through the GRU and use the output layer to get the next character distribution.\n",
        "        # return that distribution and the next hidden state.\n",
        "        # You may need to play around with the dimensions a bit until you get it right. Dimension-induced frustration is good for you!\n",
        "        # -------------------------\n",
        "        # YOUR CODE HERE\n",
        "        embedded = self.embedding(input_)[None,None,:]\n",
        "        if len(embedded.shape) == 4:\n",
        "          embedded = embedded[0]\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.output_layer(output)[0,:,:]\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.num_layers, 1, self.hidden_size))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "da793a49917dc4882e7e70f04d07a777",
          "grade": false,
          "grade_id": "cell-b9299fddeb082b4e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "aZWMbY1o8qLv"
      },
      "source": [
        "### Creating the Training Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f6eaeb80c370b32f26eda2ac1be57444",
          "grade": false,
          "grade_id": "cell-83bf9e1b0374206c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "B-ngTV6Q8qLv"
      },
      "source": [
        "Each chunk will be turned into a tensor by looping through the characters of the string and looking up the index of each character in `all_characters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cc87bca342db2fde1b3957f48bcfe857",
          "grade": false,
          "grade_id": "cell-5360afdd0b03b1f4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "98wyNtkw8qLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d8473e-f02a-4099-f646-ae96bba3059f"
      },
      "source": [
        "# Turn a string into list of longs\n",
        "def chars_to_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(chars_to_tensor('abcDEF'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f7fab2aa0d22a697fcc3d675b1821875",
          "grade": false,
          "grade_id": "cell-6e7b3d9e8c9396bb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "cYh_R1K88qLv"
      },
      "source": [
        "Now we can assemble a pair of input and target tensors (i.e. a single training example) for training, from a random chunk. The input will be all characters *except the last*, and the target will be all characters *except the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "adf90d7ec6728b2f45d1e8de5c47203c",
          "grade": false,
          "grade_id": "cell-d3539c5f1d96a188",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "QFDYhW3a8qLv"
      },
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = chars_to_tensor(chunk[:-1])\n",
        "    target = chars_to_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "18a6bf800d9bc590739b15ba01dda408",
          "grade": false,
          "grade_id": "cell-16d13f3b273395ac",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "eU6VTX8F8qLv"
      },
      "source": [
        "### Evaluating\n",
        "\n",
        "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a47c721a818979b886f119401206e756",
          "grade": false,
          "grade_id": "cell-44ab27a8fee696ad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "xeoACNc78qLv"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = model.init_hidden()\n",
        "    prime_input = chars_to_tensor(prime_str)\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = model(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = model(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist =  F.softmax(output / temperature, dim=-1)\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = chars_to_tensor(predicted_char)\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3fffa10554299eaae14cc007fea3935a",
          "grade": false,
          "grade_id": "cell-1d3fd015fe8f64d1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "iNmsUvyM8qLv"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8a98218b35f47137eeba1ba1aead0700",
          "grade": false,
          "grade_id": "cell-a209b293a8850a57",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AiCVg5Ec8qLv"
      },
      "source": [
        "The main training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb3bfcd4d49b2f2672447d8c65b6cb05",
          "grade": false,
          "grade_id": "cell-e246cbd9689e1a6d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "Wug0q2Me8qLv"
      },
      "source": [
        "def train(inp, target):\n",
        "    hidden = model.init_hidden()\n",
        "    model.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = model(inp[c], hidden)\n",
        "        loss += criterion(output, target[c].view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item() / chunk_len"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bfb863e279db4b170c35d8d0c7a37a1f",
          "grade": false,
          "grade_id": "cell-05ce9b9275e0d1cc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hFBSiQqS8qLv"
      },
      "source": [
        "A helper to print the amount of time passed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "16d7b53f211a6a1bef71c1dd2d1271cf",
          "grade": false,
          "grade_id": "cell-cb78afef7022f9a1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "vIzUAL-a8qLv"
      },
      "source": [
        "import time, math\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{m}m {math.floor(s)}s'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2b368f1767ddd0eddca44249fa47ed32",
          "grade": true,
          "grade_id": "cell-98f46bec0b8c87cc",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pAlXhasn8qLv"
      },
      "source": [
        "# DO NOT DELETE THIS CELL\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "98abd7dd7805753c2e7b635f1265cb73",
          "grade": false,
          "grade_id": "cell-baf25642209867dc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0Xva5o5I8qLv"
      },
      "source": [
        "Define the training parameters, instantiate the model, and start training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ab44452ad9f838e0b56e1fc154ab6125",
          "grade": false,
          "grade_id": "cell-4900f92ae503be69",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "pRLHP-UQ8qLw",
        "outputId": "046a502f-9382-4567-e2ac-23ac002edb76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "hidden_size = 100  # (D_h from the handout)\n",
        "num_layers = 1\n",
        "lr = 0.005\n",
        "\n",
        "model = OurModel(n_characters, hidden_size, n_characters, num_layers)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set())\n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print(f'[time elapsed: {time_since(start)}  ;  epochs: {epoch} ({epoch / n_epochs * 100}%)  ;  loss: {loss:.4}]')\n",
        "        print(evaluate('Wh', 200), '\\n')  # generate text starting with 'Wh'\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[time elapsed: 0m 25s  ;  epochs: 100 (5.0%)  ;  loss: 2.286]\n",
            "Whun shy berre stare wous, thy.\n",
            "\n",
            "Yack kir; ous for yould sthis lereal ow nolas, seainger my oof ste lis rens ine to thy sar the ou fort\n",
            "I indre ceald thy woupread youlby so som for have ous in nilk fore \n",
            "\n",
            "[time elapsed: 0m 50s  ;  epochs: 200 (10.0%)  ;  loss: 2.034]\n",
            "Wher and with I badient.\n",
            "\n",
            "PRYO:\n",
            "A, thall bet to enoson fare he doan grors soo nean boy or gi, s tor, me an lames, I doth.\n",
            "\n",
            "CETUS:\n",
            "And my and me card my wothe bent your sinke', Woto wile tell;\n",
            "Whall shav \n",
            "\n",
            "[time elapsed: 1m 15s  ;  epochs: 300 (15.0%)  ;  loss: 1.975]\n",
            "Whold Walle,\n",
            "And the and mee the what what sach him is with whath sirghtnesteard maso the cortell morwer at aw we may be you\n",
            "Whim: good he shall good sous unkent the wor cash whith thry on have gropet b \n",
            "\n",
            "[time elapsed: 1m 41s  ;  epochs: 400 (20.0%)  ;  loss: 1.974]\n",
            "Whos roge; is the rathrear\n",
            "we and the herst cerird ith pris joware\n",
            "The his that shall dife the dise this\n",
            "The die, and 'warid sow mut,\n",
            "Your O fringth, as 'tit host, would then home, partero,\n",
            "The dead you \n",
            "\n",
            "[time elapsed: 2m 6s  ;  epochs: 500 (25.0%)  ;  loss: 1.727]\n",
            "Where on we rom pemperto then I maght they nows houpan let a\n",
            "did the rive as may andy,\n",
            "Firgut mandereronce dearence memand aw;\n",
            "And see or this and less him hown theing to bay, are, comess and he welless \n",
            "\n",
            "[time elapsed: 2m 31s  ;  epochs: 600 (30.0%)  ;  loss: 1.793]\n",
            "Whould my last my good reast to your too digwing and horn will more this and of hou\n",
            "Sire sidly ist it Rimily,\n",
            "Or monce of thim good to heard.\n",
            "\n",
            "Joss for: a the sind\n",
            "Of to the com not senceen to old sours \n",
            "\n",
            "[time elapsed: 2m 56s  ;  epochs: 700 (35.0%)  ;  loss: 1.788]\n",
            "Whou strake to shore to and the to the pent the slain\n",
            "the viieds sir, And with the resa the and no that the rit--\n",
            "\n",
            "LADY ANRCELY:\n",
            "And no somes arm, the conusumion the clay\n",
            "Tares briak'ds, im for ig to th \n",
            "\n",
            "[time elapsed: 3m 21s  ;  epochs: 800 (40.0%)  ;  loss: 1.622]\n",
            "Where bother a broth that have my the chimbray.\n",
            "\n",
            "PERVIO:\n",
            "None: thight the ance thou to wathen,\n",
            "On awy and the for eight to my light.\n",
            "\n",
            "CERIZABET:\n",
            "Aght, O still will have he so worely time, a would uppy o \n",
            "\n",
            "[time elapsed: 3m 47s  ;  epochs: 900 (45.0%)  ;  loss: 1.813]\n",
            "Wherciut?\n",
            "\n",
            "MARCIUS:\n",
            "Belint metare such if the soull beding cilking to meatich these fornlely a gance\n",
            "Beiccamend the vosings at him fay; a fartelf;\n",
            "'Tis abought have prom fair, not you his precommap fly. \n",
            "\n",
            "[time elapsed: 4m 12s  ;  epochs: 1000 (50.0%)  ;  loss: 1.777]\n",
            "Which to prick and volime,\n",
            "How wouldly bing the I more toow\n",
            "Your eart made of to mampling I my though Godr.\n",
            "\n",
            "GLOUCESTERE:\n",
            "Bey give to chap'r, heir have basty,\n",
            "To to he will his be time to stands istost  \n",
            "\n",
            "[time elapsed: 4m 37s  ;  epochs: 1100 (55.00000000000001%)  ;  loss: 1.67]\n",
            "Whulks be had to bing to cally; ong able,\n",
            "Petter: your latwend of thy light be done a will sere with dear's worful one to was it\n",
            "Canst child, be-doth be were be will.\n",
            "\n",
            "LUWIO:\n",
            "Ind look of your bonges,\n",
            "Th \n",
            "\n",
            "[time elapsed: 5m 2s  ;  epochs: 1200 (60.0%)  ;  loss: 1.568]\n",
            "Wher sink'd mius muson emble our of thee of Mink;\n",
            "And as duliolin care prince etus to ever him hese enotinot;\n",
            "With when wife our husbet are of his brother,\n",
            "Me do more thou fold one our good dist my boun \n",
            "\n",
            "[time elapsed: 5m 28s  ;  epochs: 1300 (65.0%)  ;  loss: 1.655]\n",
            "Whow it yet fears thing your bast.\n",
            "\n",
            "First Lank:\n",
            "I will be with thee mude after dispirin.\n",
            "\n",
            "Prare:\n",
            "I would her, me chatt be all an rence\n",
            "Thad a have of what and will so roy;\n",
            "We hand death your mich did he \n",
            "\n",
            "[time elapsed: 5m 53s  ;  epochs: 1400 (70.0%)  ;  loss: 1.786]\n",
            "What, presive as heart your comand;\n",
            "And tho field beir news in and not his neather his wold.\n",
            "\n",
            "ANGELLO:\n",
            "The grears, fear the be my news, for marder agishing it\n",
            "Corey farence,\n",
            "Which deat be it mear to my  \n",
            "\n",
            "[time elapsed: 6m 18s  ;  epochs: 1500 (75.0%)  ;  loss: 1.599]\n",
            "WhDIUS:\n",
            "Yet, but back sorrow it, old tides the consting me.\n",
            "\n",
            "PETIUS:\n",
            "Who timed a the was ball sir, and to be knonk.\n",
            "\n",
            "QUEEN:\n",
            "The courtor canispon it thy are be the news;\n",
            "And shall that thereford beight t \n",
            "\n",
            "[time elapsed: 6m 43s  ;  epochs: 1600 (80.0%)  ;  loss: 1.679]\n",
            "Wher enting know,\n",
            "And Glouse a daughters but dore,\n",
            "Yence of marken, one\n",
            "When from asment prince his gentleman.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Hence he word it as fafe will not lepp as to.\n",
            "\n",
            "LUCENTIO:\n",
            "O, sany be as he \n",
            "\n",
            "[time elapsed: 7m 8s  ;  epochs: 1700 (85.0%)  ;  loss: 1.672]\n",
            "Whoshmursel the expact?\n",
            "Unat in it wiftiner she from such a will me,\n",
            "For mere pose my her wast in both deather\n",
            "Is and gove hoop are my landed and well did seep.\n",
            "\n",
            "SAMPSH:\n",
            "Why, what, brother, be to but it \n",
            "\n",
            "[time elapsed: 7m 33s  ;  epochs: 1800 (90.0%)  ;  loss: 1.669]\n",
            "Whitake my telove\n",
            "Dike a than a conss, being his, rath\n",
            "his handing kings inful that as agow not the\n",
            "To most gentle's there your leave of threldoight\n",
            "And lided; and so Riect shall his knows gentlemant,\n",
            "I \n",
            "\n",
            "[time elapsed: 7m 58s  ;  epochs: 1900 (95.0%)  ;  loss: 1.584]\n",
            "Wh Prviiro Lord make make yout as and cannorge.\n",
            "\n",
            "POLIXENES:\n",
            "Think our his fair ways stourting to mads counge.\n",
            "\n",
            "GLOUTHE:\n",
            "Now, I have hone hear I man in him.\n",
            "\n",
            "KING RICHARD III:\n",
            "Ny of is plamant this mad,  \n",
            "\n",
            "[time elapsed: 8m 23s  ;  epochs: 2000 (100.0%)  ;  loss: 1.764]\n",
            "Wh are nupling thee, makess.\n",
            "\n",
            "KING kinder's see slick, and hearts the part to here:\n",
            "You love a sightion brige;\n",
            "The mercher him and her sworchent what o's;\n",
            "To father but of son not me son reqiueed;\n",
            "Forfo \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8584d3be75d90a5197e7133411e0021d",
          "grade": false,
          "grade_id": "cell-ff9d72dafefa0a23",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dXeVkk298qLw"
      },
      "source": [
        "### Training Loss\n",
        "\n",
        "Plotting the the losses that were computed during training can provide a further indication that the network was indeed learning (Add your plot to the final submission pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "357a8a13a77f5e3b3e336e022dc596d4",
          "grade": false,
          "grade_id": "cell-f91bb597844b8f7d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "pycharm": {
          "is_executing": false
        },
        "id": "S2SZanbV8qLw",
        "outputId": "31d88249-3f11-439b-f319-0700ea97a4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.grid(True)\n",
        "plt.xlabel('# of epochs (divided by plot_every)')\n",
        "plt.ylabel('average loss')\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5a2f52f290>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}